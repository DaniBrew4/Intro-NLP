{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP\n",
    "The “ratings.tsv” dataset is a subset of 8000 movie reviews from a larger dataset of 25,000 movie reviews (http://ai.stanford.edu/ amaas/data/sentiment/). The goal is to build a classification model that predicts whether or not the review is positive or negative based on the words in the review.\n",
    "\n",
    "1. Import the data. Note that the dataset is tab delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   8000 non-null   object\n",
      " 1   review  7945 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 125.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check for and remove missing values and blank strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you\\'re\", \"you\\'ve\", \"you\\'ll\", \"you\\'d\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she\\'s\", 'her', 'hers', 'herself', 'it', \"it\\'s\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that\\'ll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don\\'t\", 'should', \"should\\'ve\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren\\'t\", 'couldn', \"couldn\\'t\", 'didn', \"didn\\'t\", 'doesn', \"doesn\\'t\", 'hadn', \"hadn\\'t\", 'hasn', \"hasn\\'t\", 'haven', \"haven\\'t\", 'isn', \"isn\\'t\", 'ma', 'mightn', \"mightn\\'t\", 'mustn', \"mustn\\'t\", 'needn', \"needn\\'t\", 'shan', \"shan\\'t\", 'shouldn', \"shouldn\\'t\", 'wasn', \"wasn\\'t\", 'weren', \"weren\\'t\", 'won', \"won\\'t\", 'wouldn', \"wouldn\\'t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the data into a training set and a test set. Use test size=0.33, stratify=y, and random state=801 (where y is the label positive or negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ratings.review\n",
    "y = ratings.label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, stratify = ratings.label, random_state = 801)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vectorize the data using TF-IDF. Be sure that all model development is with the training data (fit the TF-IDF transformer on the training data, then transform to both training and test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 50, stop_words=sw)\n",
    "tfidf.fit(x_train)\n",
    "X_train = tfidf.transform(x_train)\n",
    "X_test = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Build a machine learning classifier. Try out various models including: \n",
    "    • Support Vector Classifier \n",
    "    • Multilayer Perceptron \n",
    "    • Multinomial Naive Bayes \n",
    "    • (You are welcome to try other models if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8844393592677345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "yhat = nb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, yhat))\n",
    "#print(f1_score(y_test, yhat))\n",
    "#print(precision_score(y_test, yhat))\n",
    "#print(recall_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1147,  164],\n",
       "       [ 139, 1172]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.87      0.88      1311\n",
      "         pos       0.88      0.89      0.89      1311\n",
      "\n",
      "    accuracy                           0.88      2622\n",
      "   macro avg       0.88      0.88      0.88      2622\n",
      "weighted avg       0.88      0.88      0.88      2622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.89      0.90      1311\n",
      "         pos       0.89      0.91      0.90      1311\n",
      "\n",
      "    accuracy                           0.90      2622\n",
      "   macro avg       0.90      0.90      0.90      2622\n",
      "weighted avg       0.90      0.90      0.90      2622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(4, 32, 32), max_iter=10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,32,32),\n",
    "                    max_iter=10000,\n",
    "                    activation='tanh',\n",
    "                    verbose=False)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.89      0.90      1311\n",
      "         pos       0.89      0.91      0.90      1311\n",
      "\n",
      "    accuracy                           0.90      2622\n",
      "   macro avg       0.90      0.90      0.90      2622\n",
      "weighted avg       0.90      0.90      0.90      2622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (You are welcome to try other models if you want)\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.81      0.85      1311\n",
      "         pos       0.82      0.90      0.86      1311\n",
      "\n",
      "    accuracy                           0.85      2622\n",
      "   macro avg       0.86      0.85      0.85      2622\n",
      "weighted avg       0.86      0.85      0.85      2622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What model performs the best? Experiment with changing the hyper-parameters, changing the vectorizer, adding bi-grams and/or using a voting classifier to increase model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptron and Support Vector Classifier performed the best with the same f1 score of .91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. If possible, report what words are most important for distinguishing between positive and negative reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "import matplotlib.pyplot as plt\n",
    "Importance = pd.DataFrame({'Importance':rf.feature_importances_*100}, index=tfidf.get_feature_names())\n",
    "Importance = Importance.iloc[rf.feature_importances_ > 0,:]\n",
    "Importance = Importance.sort_values('Importance', axis=0, ascending=False).head(20)\n",
    "Importance.plot(kind='barh', color='r', )\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.gca().legend_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random Forest: Worst, No, Bad, Awful and Waste were the strongest negative distinguishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Using Vader sentiment analysis, predict whether or not the movie review is positive or negative. (Use a positive compound score for “positive” and a negative compound score for “negative”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/danibrew4/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...</td>\n",
       "      <td>-0.9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "      <td>{'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...</td>\n",
       "      <td>-0.8618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "      <td>{'neg': 0.068, 'neu': 0.781, 'pos': 0.15, 'com...</td>\n",
       "      <td>0.9951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "      <td>{'neg': 0.071, 'neu': 0.782, 'pos': 0.147, 'co...</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "      <td>{'neg': 0.091, 'neu': 0.817, 'pos': 0.093, 'co...</td>\n",
       "      <td>-0.2484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review  \\\n",
       "0      0   neg  how do films like mouse hunt get into theatres...   \n",
       "1      1   neg  some talented actresses are blessed with a dem...   \n",
       "2      2   pos  this has been an extraordinary year for austra...   \n",
       "3      3   pos  according to hollywood movies made in last few...   \n",
       "4      4   neg  my first press screening of 1998 and already i...   \n",
       "\n",
       "                                              scores  compound  \n",
       "0  {'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...   -0.9125  \n",
       "1  {'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...   -0.8618  \n",
       "2  {'neg': 0.068, 'neu': 0.781, 'pos': 0.15, 'com...    0.9951  \n",
       "3  {'neg': 0.071, 'neu': 0.782, 'pos': 0.147, 'co...    0.9972  \n",
       "4  {'neg': 0.091, 'neu': 0.817, 'pos': 0.093, 'co...   -0.2484  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "ratings['scores'] = ratings['review'].apply(lambda x: sid.polarity_scores(x))\n",
    "ratings['compound'] = ratings['scores'].apply(lambda x: x['compound'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. How does the accuracy of the sentiment analysis compare with that of the predictive model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danibrew4/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/danibrew4/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "/home/danibrew4/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "compound = ratings['compound']\n",
    "for i in range(len(compound)):\n",
    "    if compound[i] > 0:\n",
    "        compound[i] = 'pos'\n",
    "    else:\n",
    "        compound[i] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       neg\n",
      "1       neg\n",
      "2       pos\n",
      "3       pos\n",
      "4       neg\n",
      "       ... \n",
      "7940    pos\n",
      "7941    neg\n",
      "7942    pos\n",
      "7943    neg\n",
      "7944    pos\n",
      "Name: compound, Length: 7945, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.55      0.65      3973\n",
      "         pos       0.66      0.87      0.75      3972\n",
      "\n",
      "    accuracy                           0.71      7945\n",
      "   macro avg       0.73      0.71      0.70      7945\n",
      "weighted avg       0.73      0.71      0.70      7945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ratings['label'], compound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that well, The f1 score is much lower at .71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Try doing sentiment analysis with the TextBlob library. How does the accuracy of TextBlob sentiments compare with Vader and the predictive model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/danibrew4/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - '/home/danibrew4/nltk_data'\n",
      "    - '/home/danibrew4/anaconda3/nltk_data'\n",
      "    - '/home/danibrew4/anaconda3/share/nltk_data'\n",
      "    - '/home/danibrew4/anaconda3/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m'''Return a list of sentences.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/danibrew4/nltk_data'\n    - '/home/danibrew4/anaconda3/nltk_data'\n    - '/home/danibrew4/anaconda3/share/nltk_data'\n    - '/home/danibrew4/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1cca826ec192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-1cca826ec192>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnamedtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \"\"\"\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, include_punc, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         _word_tokenizer.itokenize(sentence, include_punc=include_punc,\n\u001b[1;32m     72\u001b[0m                                 *args, **kwargs)\n\u001b[0;32m---> 73\u001b[0;31m         for sentence in sent_tokenize(text))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/base.py\u001b[0m in \u001b[0;36mitokenize\u001b[0;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m##### SENTIMENT ANALYZERS ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "nba = NaiveBayesAnalyzer()\n",
    "ratings['scores'] = ratings['review'].apply(lambda x: TextBlob(x, analyzer=NaiveBayesAnalyzer()).sentiment)\n",
    "ratings['compound'] = ratings['scores'].apply(lambda x: x['compound'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound = ratings['compound']\n",
    "for i in range(len(compound)):\n",
    "    if compound[i] > 0:\n",
    "        compound[i] = 'pos'\n",
    "    else:\n",
    "        compound[i] = 'neg'\n",
    "print(compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ratings['label'], compound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Run LDA topic modeling using gensim on the movie reviews. How many topics are there? What are the most common words in each topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
